{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, NamedTuple\n",
    "\n",
    "import chex\n",
    "from jumanji import specs, Environment\n",
    "from jumanji.env import State\n",
    "from jumanji.types import TimeStep, restart, termination, transition\n",
    "from jumanji.viewer import Viewer\n",
    "import jumanji\n",
    "from jax.tree_util import tree_map\n",
    "from chex import dataclass\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import matplotlib\n",
    "from numpy.typing import NDArray\n",
    "from utils import idx_to_action_enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bin.game_interfaces_binding import Game, GameState, GameAction, GameOptions, ActionType, SubActionType, TileMask, Craftsman, MapState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ProconState:\n",
    "    is_pond: chex.Array\n",
    "    is_castle: chex.Array\n",
    "    has_t1_wall: chex.Array\n",
    "    has_t2_wall: chex.Array\n",
    "    has_t1_craftsman: chex.Array\n",
    "    has_t2_craftsman: chex.Array\n",
    "    is_t1_close_territory: chex.Array\n",
    "    is_t2_close_territory: chex.Array\n",
    "    is_t1_open_territory: chex.Array\n",
    "    is_t2_open_territory: chex.Array\n",
    "\n",
    "    agents: chex.Array # num_of_agents*EnvAgent\n",
    "\n",
    "    current_turn: chex.Array # ()\n",
    "    remaining_turns: chex.Array # ()\n",
    "    \n",
    "    is_t1_turn: chex.Array # ()\n",
    "    wall_coeff: chex.Array # ()\n",
    "    castle_coeff: chex.Array # ()\n",
    "    territory_coeff: chex.Array # ()\n",
    "\n",
    "    key: chex.PRNGKey # (2,)\n",
    "\n",
    "class ProconObservation(NamedTuple):\n",
    "    is_pond: chex.Array\n",
    "    is_castle: chex.Array\n",
    "    has_t1_wall: chex.Array\n",
    "    has_t2_wall: chex.Array\n",
    "    has_t1_craftsman: chex.Array\n",
    "    has_t2_craftsman: chex.Array\n",
    "    is_t1_close_territory: chex.Array\n",
    "    is_t2_close_territory: chex.Array\n",
    "    is_t1_open_territory: chex.Array\n",
    "    is_t2_open_territory: chex.Array\n",
    "\n",
    "    agents: chex.Array # num_of_agents*EnvAgent\n",
    "\n",
    "    current_turn: chex.Array # ()\n",
    "    remaining_turns: chex.Array # ()\n",
    "    \n",
    "    is_t1_turn: chex.Array # ()\n",
    "    wall_coeff: chex.Array # ()\n",
    "    castle_coeff: chex.Array # ()\n",
    "    territory_coeff: chex.Array # ()\n",
    "\n",
    "class EnvAgent(NamedTuple):\n",
    "    x: chex.Array\n",
    "    y: chex.Array\n",
    "    id: chex.Array\n",
    "    is_t1: chex.Array\n",
    "\n",
    "class EnvAction(NamedTuple):\n",
    "    action: chex.Array # ()\n",
    "    craftsman_id: chex.Array # ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.animation\n",
    "import matplotlib.cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.axes import Axes\n",
    "from numpy.typing import NDArray\n",
    "from jumanji.environments.commons.maze_utils.maze_rendering import MazeViewer\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from enum import Enum\n",
    " \n",
    "class ScoreType(Enum):\n",
    "    T1_OPEN_TERRITORY = 0\n",
    "    T2_OPEN_TERRITORY = 1\n",
    "    T1_CLOSE_TERRITORY = 2\n",
    "    T2_CLOSE_TERRITORY = 3\n",
    "    T1_WALL = 4\n",
    "    T2_WALL = 5\n",
    "    T1_CASTLE = 6\n",
    "    T2_CASTLE = 7\n",
    "    T1 = 8\n",
    "    T2 = 9\n",
    "\n",
    "def calculate_score(state: ProconState):\n",
    "    width = state.is_pond.shape[1]\n",
    "    height = state.is_pond.shape[0]\n",
    "\n",
    "    res = {\n",
    "        ScoreType.T1_OPEN_TERRITORY: 0,\n",
    "        ScoreType.T2_OPEN_TERRITORY: 0,\n",
    "        ScoreType.T1_CLOSE_TERRITORY: 0,\n",
    "        ScoreType.T2_CLOSE_TERRITORY: 0,\n",
    "        ScoreType.T1_WALL: 0,\n",
    "        ScoreType.T2_WALL: 0,\n",
    "        ScoreType.T1_CASTLE: 0,\n",
    "        ScoreType.T2_CASTLE: 0,\n",
    "        ScoreType.T1: 0,\n",
    "        ScoreType.T2: 0,\n",
    "    }\n",
    "\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            if state.is_t1_close_territory[row, col] or state.is_t1_open_territory[row, col]:\n",
    "                if state.is_t1_close_territory[row, col]:\n",
    "                    res[ScoreType.T1_CLOSE_TERRITORY] += state.territory_coeff\n",
    "                else:\n",
    "                    res[ScoreType.T1_OPEN_TERRITORY] += state.territory_coeff\n",
    "                if state.is_castle[row, col]:\n",
    "                    res[ScoreType.T1_CASTLE] += state.castle_coeff\n",
    "            elif state.is_t2_close_territory[row, col] or state.is_t2_open_territory[row, col]:\n",
    "                if state.is_t2_close_territory[row, col]:\n",
    "                    res[ScoreType.T2_CLOSE_TERRITORY] += state.territory_coeff\n",
    "                else:\n",
    "                    res[ScoreType.T2_OPEN_TERRITORY] += state.territory_coeff\n",
    "                if state.is_castle[row, col]:\n",
    "                    res[ScoreType.T2_CASTLE] += state.castle_coeff\n",
    "            elif state.has_t1_wall[row, col]:\n",
    "                res[ScoreType.T1_WALL] += state.wall_coeff\n",
    "            elif state.has_t2_wall[row, col]:\n",
    "                res[ScoreType.T2_WALL] += state.wall_coeff\n",
    "    \n",
    "    res[ScoreType.T1] = res[ScoreType.T1_OPEN_TERRITORY] + res[ScoreType.T1_CLOSE_TERRITORY] + res[ScoreType.T1_WALL] + res[ScoreType.T1_CASTLE]\n",
    "    res[ScoreType.T2] = res[ScoreType.T2_OPEN_TERRITORY] + res[ScoreType.T2_CLOSE_TERRITORY] + res[ScoreType.T2_WALL] + res[ScoreType.T2_CASTLE]\n",
    "\n",
    "    return res\n",
    "\n",
    "%matplotlib inline\n",
    "class ProconViewer(MazeViewer):\n",
    "    COLORS = {\n",
    "        \"T1_WALL\": [0, 0.024, 0.671],\n",
    "        \"T1_CLOSE_TERRITORY\": [0.133, 0.161, 1],\n",
    "        \"T1_OPEN_TERRITORY\": [0.573, 0.62, 1],\n",
    "        \"T1_CRAFTSMAN\": [0.278, 0.922, 0.906],\n",
    "        \"T2_WALL\": [0.569, 0, 0],\n",
    "        \"T2_CLOSE_TERRITORY\": [1, 0, 0],\n",
    "        \"T2_OPEN_TERRITORY\": [1, 0.635, 0.635],\n",
    "        \"T2_CRAFTSMAN\": [0.922, 0.278, 0.58],\n",
    "        \"CASTLE\": [0.988, 0.91, 0.145],\n",
    "        \"POND\": [0,0,0],\n",
    "    }\n",
    "\n",
    "    def __init__(self, name: str, render_mode: str = \"human\") -> None:\n",
    "        \"\"\"\n",
    "        Viewer for the `Procon` environment.\n",
    "\n",
    "        Args:\n",
    "            name: the window name to be used when initialising the window.\n",
    "            render_mode: the mode used to render the environment. Must be one of:\n",
    "                - \"human\": render the environment on screen.\n",
    "                - \"rgb_array\": return a numpy array frame representing the environment.\n",
    "        \"\"\"\n",
    "        super().__init__(name, render_mode)\n",
    "\n",
    "        image_names = [\n",
    "            \"c1\",\n",
    "            \"c2\",\n",
    "        ]\n",
    "\n",
    "        self._images = {name: Image.open(f\"assets/{name}.png\").resize((8,8)) for name in image_names}\n",
    "        \n",
    "    def render_with_score(self, state: ProconState) -> Optional[NDArray]:\n",
    "        self._clear_display()\n",
    "        fig, ax = self._get_fig_ax()\n",
    "        ax.clear()\n",
    "        self._add_grid_image(state, ax)\n",
    "\n",
    "        score = calculate_score(state)\n",
    "        fig.suptitle(f\"Procon - Territory: {state.territory_coeff}, Wall: {state.wall_coeff}, Castle: {state.castle_coeff}, Turns: {state.current_turn} - {datetime.now().strftime('%H:%M:%S %d-%m-%Y')}\")\n",
    "        ax.set_title(f\"Turn {state.current_turn} - Team 1: {score[ScoreType.T1]}, Team 2: {score[ScoreType.T2]}\\nT1 - Close: {score[ScoreType.T1_CLOSE_TERRITORY]}, Open: {score[ScoreType.T1_OPEN_TERRITORY]}, Wall: {score[ScoreType.T1_WALL]}, Castle: {score[ScoreType.T1_CASTLE]}\\nT2 - Close: {score[ScoreType.T2_CLOSE_TERRITORY]}, Open: {score[ScoreType.T2_OPEN_TERRITORY]}, Wall: {score[ScoreType.T2_WALL]}, Castle: {score[ScoreType.T2_CASTLE]}\")\n",
    "        return self._display(fig)\n",
    "\n",
    "    def animate_with_score(\n",
    "        self,\n",
    "        states: Sequence[ProconState],\n",
    "        interval: int = 200,\n",
    "        save_path: Optional[str] = None,\n",
    "    ) -> matplotlib.animation.FuncAnimation:\n",
    "        fig, ax = plt.subplots(num=f\"{self._name}Animation\", figsize=self.FIGURE_SIZE)\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "        fig.suptitle(f\"Procon - Territory: {states[0].territory_coeff}, Wall: {states[0].wall_coeff}, Castle: {states[0].castle_coeff}, Turns: {states[0].current_turn} - {datetime.now().strftime('%H:%M:%S %d-%m-%Y')}\")\n",
    "\n",
    "        def make_frame(state_index: int) -> None:\n",
    "            ax.clear()\n",
    "            state = states[state_index]\n",
    "            self._add_grid_image(state, ax)\n",
    "            score = calculate_score(state)\n",
    "            ax.set_title(f\"Turn {state.current_turn} - Team 1: {score[ScoreType.T1]}, Team 2: {score[ScoreType.T2]}\\nT1 - Close: {score[ScoreType.T1_CLOSE_TERRITORY]}, Open: {score[ScoreType.T1_OPEN_TERRITORY]}, Wall: {score[ScoreType.T1_WALL]}, Castle: {score[ScoreType.T1_CASTLE]}\\nT2 - Close: {score[ScoreType.T2_CLOSE_TERRITORY]}, Open: {score[ScoreType.T2_OPEN_TERRITORY]}, Wall: {score[ScoreType.T2_WALL]}, Castle: {score[ScoreType.T2_CASTLE]}\")\n",
    "\n",
    "        # Create the animation object.\n",
    "        self._animation = matplotlib.animation.FuncAnimation(\n",
    "            fig,\n",
    "            make_frame,\n",
    "            frames=len(states),\n",
    "            interval=interval,\n",
    "        )\n",
    "\n",
    "        # Save the animation as a gif.\n",
    "        if save_path:\n",
    "            self._animation.save(save_path)\n",
    "\n",
    "        return self._animation\n",
    "\n",
    "\n",
    "    def _create_grid_image(self, state: ProconState) -> NDArray:\n",
    "        img = np.ones((*state.has_t1_wall.shape, 3))\n",
    "\n",
    "        img[state.is_t1_open_territory] = self.COLORS[\"T1_OPEN_TERRITORY\"]\n",
    "        img[state.is_t2_open_territory] = self.COLORS[\"T2_OPEN_TERRITORY\"]\n",
    "        img[state.is_t1_close_territory] = self.COLORS[\"T1_CLOSE_TERRITORY\"]\n",
    "        img[state.is_t2_close_territory] = self.COLORS[\"T2_CLOSE_TERRITORY\"]\n",
    "\n",
    "        img[state.has_t1_wall] = self.COLORS[\"T1_WALL\"]\n",
    "        img[state.has_t2_wall] = self.COLORS[\"T2_WALL\"]\n",
    "\n",
    "        img[state.is_castle] = self.COLORS[\"CASTLE\"]\n",
    "        img[state.is_pond] = self.COLORS[\"POND\"]\n",
    "\n",
    "        # add a transparent layer\n",
    "        img = np.dstack([img, np.ones(img.shape[:2])])\n",
    "\n",
    "        # upscale array by 8 times\n",
    "        img = np.kron(img, np.ones((8, 8, 1)))\n",
    "\n",
    "        img = Image.fromarray((img * 255).astype('uint8'))\n",
    "\n",
    "        # paste the craftsman on top\n",
    "        for agent in state.agents:\n",
    "            if agent.is_t1:\n",
    "                img.paste(self._images[\"c1\"], (agent.x*8, agent.y*8), self._images[\"c1\"])\n",
    "            else:\n",
    "                img.paste(self._images[\"c2\"], (agent.x*8, agent.y*8), self._images[\"c2\"])\n",
    "        \n",
    "        img = np.array(img)\n",
    "\n",
    "        img = self._draw_black_frame_around(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "    def _draw_black_frame_around(self, img: NDArray) -> NDArray:\n",
    "        img = np.pad(img, ((8, 8), (8, 8), (0, 0)),mode='constant', constant_values=255)\n",
    "        img[:8, :, :3] = img[-8:, :, :3] = img[:, :8, :3] = img[:, -8:, :3] = 0\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T10:55:43.338539Z",
     "start_time": "2023-11-24T10:55:43.220493Z"
    }
   },
   "outputs": [],
   "source": [
    "max_possible_actions = 17\n",
    "\n",
    "class ProconJumanji(Environment[ProconState]):\n",
    "    def __init__(self, gameOptions: GameOptions, map: list[list[int]], craftsmen: list[Craftsman]):\n",
    "        self.max_turns = gameOptions.maxTurns\n",
    "        self.map_width = gameOptions.mapWidth\n",
    "        self.map_height = gameOptions.mapHeight\n",
    "\n",
    "        self.num_agents = len(craftsmen)\n",
    "\n",
    "        self.game = Game(gameOptions, map, craftsmen)\n",
    "        self.game_options = gameOptions\n",
    "\n",
    "        self._viewer = ProconViewer(\"Procon\", render_mode=\"human\")\n",
    "\n",
    "        self.initial_state = self._game_state_to_env_state(self.game.getCurrentState(), self.game.gameOptions)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"Procon(\\n\"\n",
    "            f\"\\tmap_width={self.map_width},\\n\"\n",
    "            f\"\\tmap_height={self.map_height},\\n\"\n",
    "            f\"\\tnum_agents={self.num_agents!r}, \\n\"\n",
    "            \")\"\n",
    "        )\n",
    "\n",
    "    def reset(self, key: chex.PRNGKey) -> Tuple[ProconState, TimeStep]:\n",
    "        state = self.initial_state\n",
    "        timestep = restart(observation=self._env_state_to_observation(state), extras=None)\n",
    "\n",
    "        return state, timestep\n",
    "        \n",
    "\n",
    "    def step(self, state: ProconState, actions: chex.Array) -> Tuple[ProconState, TimeStep[ProconObservation]]:\n",
    "        game_state = self._env_state_to_game_state(state)\n",
    "        game_actions = self._env_actions_to_game_actions(actions)\n",
    "        \n",
    "        next_game_state = game_state.applyActions(game_actions)\n",
    "\n",
    "        print(actions)\n",
    "\n",
    "        for game_action in game_actions:\n",
    "            print(game_action.craftsmanId, game_action.actionType, game_action.subActionType)\n",
    "\n",
    "        print(next_game_state.map.calcPoints(self.game.gameOptions, True), next_game_state.map.calcPoints(self.game.gameOptions, False))\n",
    "\n",
    "        next_env_state = self._game_state_to_env_state(next_game_state, self.game.gameOptions)\n",
    "\n",
    "        next_observation = self._env_state_to_observation(next_env_state)\n",
    "\n",
    "        t1_score_prev, t2_score_prev = game_state.map.calcPoints(self.game.gameOptions, True), game_state.map.calcPoints(self.game.gameOptions, False)\n",
    "        t1_score_next, t2_score_next = next_game_state.map.calcPoints(self.game.gameOptions, True), next_game_state.map.calcPoints(self.game.gameOptions, False)\n",
    "\n",
    "        reward = np.array([t1_score_next - t1_score_prev, t2_score_next - t2_score_prev])\n",
    "        done = game_state\n",
    "\n",
    "        # timestep = jax.lax.cond(\n",
    "        #     done,\n",
    "        #     lambda reward, observation, extras: termination(\n",
    "        #         reward=reward,\n",
    "        #         observation=observation,\n",
    "        #         extras=extras,\n",
    "        #     ),\n",
    "        #     lambda reward, observation, extras: transition(\n",
    "        #         reward=reward,\n",
    "        #         observation=observation,\n",
    "        #         extras=extras,\n",
    "        #     ),\n",
    "        #     reward,\n",
    "        #     next_observation,\n",
    "        #     None,\n",
    "        # )\n",
    "\n",
    "        timestep = termination(\n",
    "                reward=reward,\n",
    "                observation=next_observation,\n",
    "                extras=None,\n",
    "        ) if done else transition(\n",
    "            reward=reward,\n",
    "            observation=next_observation,\n",
    "            extras=None,\n",
    "        )\n",
    "\n",
    "        return next_env_state, timestep\n",
    "\n",
    "\n",
    "\n",
    "    def observation_spec(self) -> specs.Spec[ProconObservation]:\n",
    "        \"\"\"agent encoding: (x, y, id, is_t1)\"\"\"\n",
    "        def boolArrayOfMapSize(name: str):\n",
    "            return specs.BoundedArray(\n",
    "                shape=(self.map_height, self.map_width), \n",
    "                dtype=bool, \n",
    "                minimum=False, \n",
    "                maximum=True, \n",
    "                name=name\n",
    "            )\n",
    "\n",
    "        return specs.Spec(\n",
    "            ProconObservation,\n",
    "            \"ObservationSpec\",\n",
    "            is_pond=boolArrayOfMapSize(\"is_pond\"),\n",
    "            is_castle=boolArrayOfMapSize(\"is_castle\"),\n",
    "            has_t1_wall=boolArrayOfMapSize(\"has_t1_wall\"),\n",
    "            has_t2_wall=boolArrayOfMapSize(\"has_t2_wall\"),\n",
    "            has_t1_craftsman=boolArrayOfMapSize(\"has_t1_craftsman\"),\n",
    "            has_t2_craftsman=boolArrayOfMapSize(\"has_t2_craftsman\"),\n",
    "            is_t1_close_territory=boolArrayOfMapSize(\"is_t1_close_territory\"),\n",
    "            is_t2_close_territory=boolArrayOfMapSize(\"is_t2_close_territory\"),\n",
    "            is_t1_open_territory=boolArrayOfMapSize(\"is_t1_open_territory\"),\n",
    "            is_t2_open_territory=boolArrayOfMapSize(\"is_t2_open_territory\"),\n",
    "            \n",
    "            agents=specs.MultiDiscreteArray(num_values=jnp.array([[self.map_width, self.map_height, self.num_agents, 2]]*self.num_agents), dtype=jnp.int32, name=\"agents\"),\n",
    "            current_turn=specs.BoundedArray((), dtype=jnp.int32, minimum=0, maximum=self.max_turns, name=\"current_turn\"),\n",
    "            remaining_turns=specs.BoundedArray((), dtype=jnp.int32, minimum=0, maximum=self.max_turns, name=\"remaining_turns\"),\n",
    "            is_t1_turn=specs.BoundedArray((), dtype=bool, minimum=False, maximum=True, name=\"is_t1_turn\"),\n",
    "        )\n",
    "\n",
    "    def action_spec(self) -> specs.Spec:\n",
    "        # (action + craftsman_id) in an array so that their is an order\n",
    "        return specs.MultiDiscreteArray(num_values=jnp.array([[max_possible_actions, self.num_agents]]*self.num_agents, dtype=jnp.int32), name=\"action\")\n",
    "    \n",
    "    def _game_state_to_env_state(self, game_state: GameState, game_options: GameOptions) -> ProconState:\n",
    "        map_state = game_state.map\n",
    "        map = np.array(map_state.tiles)\n",
    "\n",
    "        agents = [EnvAgent(craftsman.x, craftsman.y, craftsman.id, craftsman.isT1) for craftsman in game_state.craftsmen.values()]\n",
    "\n",
    "        state = ProconState(\n",
    "            is_pond=map & (1 << TileMask.POND.value) > 0,\n",
    "            is_castle=map & (1 << TileMask.CASTLE.value) > 0,\n",
    "            has_t1_wall=map & (1 << TileMask.T1_WALL.value) > 0,\n",
    "            has_t2_wall=map & (1 << TileMask.T2_WALL.value) > 0,\n",
    "            has_t1_craftsman=map & (1 << TileMask.T1_CRAFTSMAN.value) > 0,\n",
    "            has_t2_craftsman=map & (1 << TileMask.T2_CRAFTSMAN.value) > 0,\n",
    "            is_t1_close_territory=map & (1 << TileMask.T1_CLOSE_TERRITORY.value) > 0,\n",
    "            is_t2_close_territory=map & (1 << TileMask.T2_CLOSE_TERRITORY.value) > 0,\n",
    "            is_t1_open_territory=map & (1 << TileMask.T1_OPEN_TERRITORY.value) > 0,\n",
    "            is_t2_open_territory=map & (1 << TileMask.T2_OPEN_TERRITORY.value) > 0,\n",
    "\n",
    "            agents=agents,\n",
    "\n",
    "            current_turn=game_state.turn,\n",
    "            remaining_turns=self.max_turns - game_state.turn,\n",
    "\n",
    "            is_t1_turn=game_state.isT1Turn,\n",
    "            wall_coeff=game_options.wallCoeff,\n",
    "            castle_coeff=game_options.castleCoeff,\n",
    "            territory_coeff=game_options.territoryCoeff,\n",
    "            key=jax.random.PRNGKey(0), # TODO: fix this\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    def _env_state_to_game_state(self, env_state: ProconState) -> GameState:\n",
    "        go = self.game.gameOptions\n",
    "        map_state = MapState(go.mapWidth, go.mapHeight)\n",
    "        map = np.zeros_like(np.array(map_state.tiles), dtype=jnp.int32)\n",
    "\n",
    "        map |= env_state.is_pond << TileMask.POND.value\n",
    "        map |= env_state.is_castle << TileMask.CASTLE.value\n",
    "        map |= env_state.has_t1_wall << TileMask.T1_WALL.value\n",
    "        map |= env_state.has_t2_wall << TileMask.T2_WALL.value\n",
    "        map |= env_state.has_t1_craftsman << TileMask.T1_CRAFTSMAN.value\n",
    "        map |= env_state.has_t2_craftsman << TileMask.T2_CRAFTSMAN.value\n",
    "        map |= env_state.is_t1_close_territory << TileMask.T1_CLOSE_TERRITORY.value\n",
    "        map |= env_state.is_t2_close_territory << TileMask.T2_CLOSE_TERRITORY.value\n",
    "        map |= env_state.is_t1_open_territory << TileMask.T1_OPEN_TERRITORY.value\n",
    "        map |= env_state.is_t2_open_territory << TileMask.T2_OPEN_TERRITORY.value\n",
    "\n",
    "\n",
    "        map_state.tiles = map.tolist()\n",
    "\n",
    "        craftsmen = {int(craftsman.id): Craftsman(craftsman.id, craftsman.x, craftsman.y, craftsman.is_t1) for craftsman in env_state.agents}\n",
    "\n",
    "        game_state = GameState(map_state, craftsmen, env_state.current_turn, env_state.is_t1_turn)\n",
    "        return game_state\n",
    "\n",
    "\n",
    "    def _env_state_to_observation(self, env_state: ProconState) -> ProconObservation:\n",
    "        return ProconObservation(\n",
    "            is_pond=env_state.is_pond,\n",
    "            is_castle=env_state.is_castle,\n",
    "            has_t1_wall=env_state.has_t1_wall,\n",
    "            has_t2_wall=env_state.has_t2_wall,\n",
    "            has_t1_craftsman=env_state.has_t1_craftsman,\n",
    "            has_t2_craftsman=env_state.has_t2_craftsman,\n",
    "            is_t1_close_territory=env_state.is_t1_close_territory,\n",
    "            is_t2_close_territory=env_state.is_t2_close_territory,\n",
    "            is_t1_open_territory=env_state.is_t1_open_territory,\n",
    "            is_t2_open_territory=env_state.is_t2_open_territory,\n",
    "\n",
    "            agents=env_state.agents,\n",
    "\n",
    "            current_turn=env_state.current_turn,\n",
    "            remaining_turns=env_state.remaining_turns,\n",
    "\n",
    "            is_t1_turn=env_state.is_t1_turn,\n",
    "            wall_coeff=env_state.wall_coeff,\n",
    "            castle_coeff=env_state.castle_coeff,\n",
    "            territory_coeff=env_state.territory_coeff,\n",
    "        )\n",
    "\n",
    "    def _env_action_to_game_action(self, env_action: EnvAction) -> GameAction:\n",
    "        return GameAction(env_action.craftsman_id, *idx_to_action_enum(env_action.action))\n",
    "\n",
    "    def _env_actions_to_game_actions(self, env_actions: chex.Array) -> chex.Array:\n",
    "        return [self._env_action_to_game_action(env_action) for env_action in env_actions]\n",
    "\n",
    "\n",
    "    def render(self, state: ProconState) -> Optional[NDArray]:\n",
    "        return self._viewer.render_with_score(state)\n",
    "\n",
    "    def animate(\n",
    "        self,\n",
    "        states: Sequence[ProconState],\n",
    "        interval: int = 200,\n",
    "        save_path: Optional[str] = None,\n",
    "    ) -> matplotlib.animation.FuncAnimation:\n",
    "        return self._viewer.animate_with_score(states, interval, save_path)\n",
    "\n",
    "# ENV_ID = \"Procon-v0\"\n",
    "# if not ENV_ID in _REGISTRY:\n",
    "#     register(id=\"Procon-v0\", entry_point=\"procon:ProconJumanji\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "action_path = \"test-cases/match-259.txt\"\n",
    "map_path = \"test-cases/map-259-game-2.txt\"\n",
    "\n",
    "from utils import load_offline_game, load_offline_actions\n",
    "\n",
    "game_options, map, craftsmen, craftsman_strid_to_intid = load_offline_game(map_path)\n",
    "\n",
    "actions = load_offline_actions(action_path, craftsman_strid_to_intid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EnvAction(action=5, craftsman_id=0), EnvAction(action=4, craftsman_id=2), EnvAction(action=2, craftsman_id=3), EnvAction(action=4, craftsman_id=1)]\n",
      "0 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "2 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "3 ActionType.MOVE SubActionType.MOVE_LEFT\n",
      "1 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "0 0\n",
      "[EnvAction(action=3, craftsman_id=4), EnvAction(action=1, craftsman_id=5), EnvAction(action=10, craftsman_id=6), EnvAction(action=10, craftsman_id=7)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "5 ActionType.MOVE SubActionType.MOVE_DOWN\n",
      "6 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "7 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "0 2\n",
      "[EnvAction(action=9, craftsman_id=0), EnvAction(action=4, craftsman_id=1), EnvAction(action=4, craftsman_id=2), EnvAction(action=9, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "1 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "2 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "3 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "2 2\n",
      "[EnvAction(action=7, craftsman_id=4), EnvAction(action=6, craftsman_id=5), EnvAction(action=4, craftsman_id=6), EnvAction(action=8, craftsman_id=7)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_DOWN_RIGHT\n",
      "5 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "6 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "7 ActionType.BUILD SubActionType.BUILD_UP\n",
      "2 3\n",
      "[EnvAction(action=8, craftsman_id=0), EnvAction(action=4, craftsman_id=1), EnvAction(action=6, craftsman_id=2), EnvAction(action=8, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_UP\n",
      "1 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "2 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "3 ActionType.BUILD SubActionType.BUILD_UP\n",
      "4 3\n",
      "[]\n",
      "4 3\n",
      "[EnvAction(action=10, craftsman_id=0), EnvAction(action=6, craftsman_id=1), EnvAction(action=6, craftsman_id=2), EnvAction(action=10, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "1 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "2 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "3 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "6 3\n",
      "[EnvAction(action=10, craftsman_id=4), EnvAction(action=8, craftsman_id=5), EnvAction(action=2, craftsman_id=6), EnvAction(action=5, craftsman_id=7)]\n",
      "4 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "5 ActionType.BUILD SubActionType.BUILD_UP\n",
      "6 ActionType.MOVE SubActionType.MOVE_LEFT\n",
      "7 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "6 5\n",
      "[EnvAction(action=7, craftsman_id=0), EnvAction(action=8, craftsman_id=1), EnvAction(action=9, craftsman_id=2), EnvAction(action=7, craftsman_id=3)]\n",
      "0 ActionType.MOVE SubActionType.MOVE_DOWN_RIGHT\n",
      "1 ActionType.BUILD SubActionType.BUILD_UP\n",
      "2 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "3 ActionType.MOVE SubActionType.MOVE_DOWN_RIGHT\n",
      "8 5\n",
      "[EnvAction(action=8, craftsman_id=4), EnvAction(action=2, craftsman_id=5), EnvAction(action=9, craftsman_id=6), EnvAction(action=8, craftsman_id=7)]\n",
      "4 ActionType.BUILD SubActionType.BUILD_UP\n",
      "5 ActionType.MOVE SubActionType.MOVE_LEFT\n",
      "6 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "7 ActionType.BUILD SubActionType.BUILD_UP\n",
      "8 8\n",
      "[EnvAction(action=9, craftsman_id=0), EnvAction(action=9, craftsman_id=1), EnvAction(action=8, craftsman_id=2), EnvAction(action=9, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "1 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "2 ActionType.BUILD SubActionType.BUILD_UP\n",
      "3 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "12 8\n",
      "[]\n",
      "12 8\n",
      "[EnvAction(action=11, craftsman_id=0), EnvAction(action=10, craftsman_id=1), EnvAction(action=10, craftsman_id=2), EnvAction(action=11, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "1 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "2 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "3 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "16 8\n",
      "[]\n",
      "16 8\n",
      "[EnvAction(action=5, craftsman_id=0), EnvAction(action=11, craftsman_id=1), EnvAction(action=7, craftsman_id=2), EnvAction(action=5, craftsman_id=3)]\n",
      "0 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "1 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "2 ActionType.MOVE SubActionType.MOVE_DOWN_RIGHT\n",
      "3 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "42 8\n",
      "[]\n",
      "42 8\n",
      "[EnvAction(action=8, craftsman_id=0), EnvAction(action=4, craftsman_id=1), EnvAction(action=9, craftsman_id=2), EnvAction(action=8, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_UP\n",
      "1 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "2 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "3 ActionType.BUILD SubActionType.BUILD_UP\n",
      "45 8\n",
      "[EnvAction(action=5, craftsman_id=4), EnvAction(action=8, craftsman_id=5), EnvAction(action=3, craftsman_id=6), EnvAction(action=3, craftsman_id=7)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "5 ActionType.BUILD SubActionType.BUILD_UP\n",
      "6 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "7 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "45 9\n",
      "[EnvAction(action=11, craftsman_id=0), EnvAction(action=6, craftsman_id=1), EnvAction(action=11, craftsman_id=2), EnvAction(action=11, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "1 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "2 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "3 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "48 9\n",
      "[EnvAction(action=8, craftsman_id=4), EnvAction(action=2, craftsman_id=5), EnvAction(action=11, craftsman_id=6), EnvAction(action=8, craftsman_id=7)]\n",
      "4 ActionType.BUILD SubActionType.BUILD_UP\n",
      "5 ActionType.MOVE SubActionType.MOVE_LEFT\n",
      "6 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "7 ActionType.BUILD SubActionType.BUILD_UP\n",
      "48 12\n",
      "[EnvAction(action=4, craftsman_id=0), EnvAction(action=6, craftsman_id=1), EnvAction(action=5, craftsman_id=2), EnvAction(action=4, craftsman_id=3)]\n",
      "0 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "1 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "2 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "3 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "48 12\n",
      "[EnvAction(action=3, craftsman_id=4), EnvAction(action=8, craftsman_id=5), EnvAction(action=8, craftsman_id=6), EnvAction(action=11, craftsman_id=7)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "5 ActionType.BUILD SubActionType.BUILD_UP\n",
      "6 ActionType.BUILD SubActionType.BUILD_UP\n",
      "7 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "48 15\n",
      "[EnvAction(action=8, craftsman_id=0), EnvAction(action=8, craftsman_id=1), EnvAction(action=8, craftsman_id=2), EnvAction(action=8, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_UP\n",
      "1 ActionType.BUILD SubActionType.BUILD_UP\n",
      "2 ActionType.BUILD SubActionType.BUILD_UP\n",
      "3 ActionType.BUILD SubActionType.BUILD_UP\n",
      "122 15\n",
      "[EnvAction(action=0, craftsman_id=4), EnvAction(action=2, craftsman_id=5), EnvAction(action=4, craftsman_id=6), EnvAction(action=7, craftsman_id=7)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_UP\n",
      "5 ActionType.MOVE SubActionType.MOVE_LEFT\n",
      "6 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "7 ActionType.MOVE SubActionType.MOVE_DOWN_RIGHT\n",
      "122 15\n",
      "[EnvAction(action=5, craftsman_id=0), EnvAction(action=9, craftsman_id=1), EnvAction(action=11, craftsman_id=2), EnvAction(action=5, craftsman_id=3)]\n",
      "0 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "1 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "2 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "3 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "124 15\n",
      "[EnvAction(action=8, craftsman_id=4), EnvAction(action=8, craftsman_id=5), EnvAction(action=10, craftsman_id=6), EnvAction(action=11, craftsman_id=7)]\n",
      "4 ActionType.BUILD SubActionType.BUILD_UP\n",
      "5 ActionType.BUILD SubActionType.BUILD_UP\n",
      "6 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "7 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "124 19\n",
      "[EnvAction(action=8, craftsman_id=0), EnvAction(action=10, craftsman_id=1), EnvAction(action=4, craftsman_id=2), EnvAction(action=8, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_UP\n",
      "1 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "2 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "3 ActionType.BUILD SubActionType.BUILD_UP\n",
      "127 19\n",
      "[EnvAction(action=6, craftsman_id=4), EnvAction(action=3, craftsman_id=5), EnvAction(action=6, craftsman_id=6), EnvAction(action=7, craftsman_id=7)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "5 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "6 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "7 ActionType.MOVE SubActionType.MOVE_DOWN_RIGHT\n",
      "127 19\n",
      "[EnvAction(action=7, craftsman_id=0), EnvAction(action=11, craftsman_id=1), EnvAction(action=8, craftsman_id=2), EnvAction(action=7, craftsman_id=3)]\n",
      "0 ActionType.MOVE SubActionType.MOVE_DOWN_RIGHT\n",
      "1 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "2 ActionType.BUILD SubActionType.BUILD_UP\n",
      "3 ActionType.MOVE SubActionType.MOVE_DOWN_RIGHT\n",
      "179 19\n",
      "[EnvAction(action=6, craftsman_id=4), EnvAction(action=3, craftsman_id=5), EnvAction(action=10, craftsman_id=6), EnvAction(action=11, craftsman_id=7)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "5 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "6 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "7 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "179 21\n",
      "[EnvAction(action=11, craftsman_id=0), EnvAction(action=4, craftsman_id=1), EnvAction(action=5, craftsman_id=2), EnvAction(action=11, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "1 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "2 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "3 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "181 21\n",
      "[EnvAction(action=1, craftsman_id=4), EnvAction(action=3, craftsman_id=5), EnvAction(action=5, craftsman_id=6), EnvAction(action=1, craftsman_id=7)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_DOWN\n",
      "5 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "6 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "7 ActionType.MOVE SubActionType.MOVE_DOWN\n",
      "181 21\n",
      "[EnvAction(action=5, craftsman_id=0), EnvAction(action=10, craftsman_id=1), EnvAction(action=8, craftsman_id=2), EnvAction(action=5, craftsman_id=3)]\n",
      "0 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "1 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "2 ActionType.BUILD SubActionType.BUILD_UP\n",
      "3 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "183 21\n",
      "[EnvAction(action=10, craftsman_id=4), EnvAction(action=11, craftsman_id=5), EnvAction(action=8, craftsman_id=6), EnvAction(action=11, craftsman_id=7)]\n",
      "4 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "5 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "6 ActionType.BUILD SubActionType.BUILD_UP\n",
      "7 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "183 25\n",
      "[EnvAction(action=8, craftsman_id=0), EnvAction(action=5, craftsman_id=1), EnvAction(action=7, craftsman_id=2), EnvAction(action=8, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_UP\n",
      "1 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "2 ActionType.MOVE SubActionType.MOVE_DOWN_RIGHT\n",
      "3 ActionType.BUILD SubActionType.BUILD_UP\n",
      "185 25\n",
      "[EnvAction(action=9, craftsman_id=4), EnvAction(action=1, craftsman_id=5), EnvAction(action=6, craftsman_id=6), EnvAction(action=1, craftsman_id=7)]\n",
      "4 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "5 ActionType.MOVE SubActionType.MOVE_DOWN\n",
      "6 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "7 ActionType.MOVE SubActionType.MOVE_DOWN\n",
      "185 26\n",
      "[EnvAction(action=11, craftsman_id=0), EnvAction(action=11, craftsman_id=1), EnvAction(action=11, craftsman_id=2), EnvAction(action=11, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "1 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "2 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "3 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "199 26\n",
      "[EnvAction(action=11, craftsman_id=4), EnvAction(action=9, craftsman_id=5), EnvAction(action=9, craftsman_id=6), EnvAction(action=11, craftsman_id=7)]\n",
      "4 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "5 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "6 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "7 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "199 50\n",
      "[EnvAction(action=4, craftsman_id=0), EnvAction(action=4, craftsman_id=1), EnvAction(action=5, craftsman_id=2), EnvAction(action=4, craftsman_id=3)]\n",
      "0 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "1 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "2 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "3 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "199 50\n",
      "[EnvAction(action=5, craftsman_id=4), EnvAction(action=11, craftsman_id=5), EnvAction(action=6, craftsman_id=6), EnvAction(action=9, craftsman_id=7)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "5 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "6 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "7 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "199 52\n",
      "[EnvAction(action=15, craftsman_id=1), EnvAction(action=8, craftsman_id=0), EnvAction(action=8, craftsman_id=2), EnvAction(action=8, craftsman_id=3)]\n",
      "1 ActionType.DESTROY SubActionType.DESTROY_RIGHT\n",
      "0 ActionType.BUILD SubActionType.BUILD_UP\n",
      "2 ActionType.BUILD SubActionType.BUILD_UP\n",
      "3 ActionType.BUILD SubActionType.BUILD_UP\n",
      "257 51\n",
      "[EnvAction(action=7, craftsman_id=4), EnvAction(action=2, craftsman_id=5), EnvAction(action=9, craftsman_id=6), EnvAction(action=10, craftsman_id=7)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_DOWN_RIGHT\n",
      "5 ActionType.MOVE SubActionType.MOVE_LEFT\n",
      "6 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "7 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "257 53\n",
      "[EnvAction(action=4, craftsman_id=0), EnvAction(action=4, craftsman_id=1), EnvAction(action=11, craftsman_id=2), EnvAction(action=4, craftsman_id=3)]\n",
      "0 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "1 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "2 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "3 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "258 53\n",
      "[EnvAction(action=9, craftsman_id=4), EnvAction(action=11, craftsman_id=5), EnvAction(action=10, craftsman_id=6), EnvAction(action=0, craftsman_id=7)]\n",
      "4 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "5 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "6 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "7 ActionType.MOVE SubActionType.MOVE_UP\n",
      "258 61\n",
      "[EnvAction(action=8, craftsman_id=0), EnvAction(action=4, craftsman_id=1), EnvAction(action=4, craftsman_id=2), EnvAction(action=8, craftsman_id=3)]\n",
      "0 ActionType.BUILD SubActionType.BUILD_UP\n",
      "1 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "2 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "3 ActionType.BUILD SubActionType.BUILD_UP\n",
      "260 61\n",
      "[EnvAction(action=11, craftsman_id=4), EnvAction(action=9, craftsman_id=5), EnvAction(action=1, craftsman_id=6), EnvAction(action=6, craftsman_id=7)]\n",
      "4 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "5 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "6 ActionType.MOVE SubActionType.MOVE_DOWN\n",
      "7 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "260 63\n",
      "[EnvAction(action=10, craftsman_id=3), EnvAction(action=4, craftsman_id=0), EnvAction(action=6, craftsman_id=1), EnvAction(action=8, craftsman_id=2)]\n",
      "3 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "0 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "1 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "2 ActionType.BUILD SubActionType.BUILD_UP\n",
      "292 63\n",
      "[EnvAction(action=5, craftsman_id=4), EnvAction(action=4, craftsman_id=5), EnvAction(action=1, craftsman_id=6), EnvAction(action=10, craftsman_id=7)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "5 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "6 ActionType.MOVE SubActionType.MOVE_DOWN\n",
      "7 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "292 64\n",
      "[EnvAction(action=4, craftsman_id=3), EnvAction(action=6, craftsman_id=1), EnvAction(action=4, craftsman_id=2)]\n",
      "3 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "1 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "2 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "292 64\n",
      "[EnvAction(action=11, craftsman_id=4), EnvAction(action=4, craftsman_id=5), EnvAction(action=10, craftsman_id=6), EnvAction(action=4, craftsman_id=7)]\n",
      "4 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "5 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "6 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "7 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "292 166\n",
      "[EnvAction(action=8, craftsman_id=1), EnvAction(action=8, craftsman_id=2), EnvAction(action=3, craftsman_id=3)]\n",
      "1 ActionType.BUILD SubActionType.BUILD_UP\n",
      "2 ActionType.BUILD SubActionType.BUILD_UP\n",
      "3 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "294 166\n",
      "[EnvAction(action=7, craftsman_id=4), EnvAction(action=5, craftsman_id=5), EnvAction(action=1, craftsman_id=6)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_DOWN_RIGHT\n",
      "5 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "6 ActionType.MOVE SubActionType.MOVE_DOWN\n",
      "294 166\n",
      "[EnvAction(action=13, craftsman_id=1), EnvAction(action=4, craftsman_id=2), EnvAction(action=2, craftsman_id=3)]\n",
      "1 ActionType.DESTROY SubActionType.DESTROY_DOWN\n",
      "2 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "3 ActionType.MOVE SubActionType.MOVE_LEFT\n",
      "294 160\n",
      "[]\n",
      "294 160\n",
      "[EnvAction(action=3, craftsman_id=3), EnvAction(action=9, craftsman_id=1), EnvAction(action=8, craftsman_id=2)]\n",
      "3 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "1 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "2 ActionType.BUILD SubActionType.BUILD_UP\n",
      "296 160\n",
      "[EnvAction(action=10, craftsman_id=4), EnvAction(action=11, craftsman_id=5), EnvAction(action=10, craftsman_id=6), EnvAction(action=10, craftsman_id=7)]\n",
      "4 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "5 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "6 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "7 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "296 163\n",
      "[EnvAction(action=10, craftsman_id=1), EnvAction(action=10, craftsman_id=2), EnvAction(action=3, craftsman_id=3)]\n",
      "1 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "2 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "3 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "298 158\n",
      "[EnvAction(action=4, craftsman_id=4), EnvAction(action=6, craftsman_id=5), EnvAction(action=9, craftsman_id=6)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "5 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "6 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "298 159\n",
      "[EnvAction(action=3, craftsman_id=3), EnvAction(action=11, craftsman_id=1), EnvAction(action=6, craftsman_id=2)]\n",
      "3 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "1 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "2 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "324 129\n",
      "[EnvAction(action=4, craftsman_id=4), EnvAction(action=0, craftsman_id=5)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "5 ActionType.MOVE SubActionType.MOVE_UP\n",
      "324 129\n",
      "[EnvAction(action=5, craftsman_id=3)]\n",
      "3 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "324 129\n",
      "[EnvAction(action=10, craftsman_id=4), EnvAction(action=4, craftsman_id=5), EnvAction(action=3, craftsman_id=6), EnvAction(action=4, craftsman_id=7)]\n",
      "4 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "5 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "6 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "7 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "324 129\n",
      "[EnvAction(action=5, craftsman_id=3)]\n",
      "3 ActionType.MOVE SubActionType.MOVE_UP_RIGHT\n",
      "324 129\n",
      "[EnvAction(action=14, craftsman_id=4), EnvAction(action=13, craftsman_id=5), EnvAction(action=9, craftsman_id=6), EnvAction(action=10, craftsman_id=7)]\n",
      "4 ActionType.DESTROY SubActionType.DESTROY_LEFT\n",
      "5 ActionType.DESTROY SubActionType.DESTROY_DOWN\n",
      "6 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "7 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "322 201\n",
      "[EnvAction(action=8, craftsman_id=1), EnvAction(action=9, craftsman_id=2)]\n",
      "1 ActionType.BUILD SubActionType.BUILD_UP\n",
      "2 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "324 201\n",
      "[EnvAction(action=13, craftsman_id=4), EnvAction(action=12, craftsman_id=5), EnvAction(action=3, craftsman_id=6), EnvAction(action=4, craftsman_id=7)]\n",
      "4 ActionType.DESTROY SubActionType.DESTROY_DOWN\n",
      "5 ActionType.DESTROY SubActionType.DESTROY_UP\n",
      "6 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "7 ActionType.MOVE SubActionType.MOVE_UP_LEFT\n",
      "322 201\n",
      "[EnvAction(action=15, craftsman_id=3), EnvAction(action=11, craftsman_id=1), EnvAction(action=10, craftsman_id=2)]\n",
      "3 ActionType.DESTROY SubActionType.DESTROY_RIGHT\n",
      "1 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "2 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "349 200\n",
      "[EnvAction(action=14, craftsman_id=4), EnvAction(action=15, craftsman_id=5), EnvAction(action=9, craftsman_id=6), EnvAction(action=10, craftsman_id=7)]\n",
      "4 ActionType.DESTROY SubActionType.DESTROY_LEFT\n",
      "5 ActionType.DESTROY SubActionType.DESTROY_RIGHT\n",
      "6 ActionType.BUILD SubActionType.BUILD_DOWN\n",
      "7 ActionType.BUILD SubActionType.BUILD_LEFT\n",
      "347 202\n",
      "[EnvAction(action=8, craftsman_id=1), EnvAction(action=6, craftsman_id=2), EnvAction(action=11, craftsman_id=3)]\n",
      "1 ActionType.BUILD SubActionType.BUILD_UP\n",
      "2 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "3 ActionType.BUILD SubActionType.BUILD_RIGHT\n",
      "348 202\n",
      "[EnvAction(action=0, craftsman_id=4), EnvAction(action=13, craftsman_id=5), EnvAction(action=3, craftsman_id=6), EnvAction(action=6, craftsman_id=7)]\n",
      "4 ActionType.MOVE SubActionType.MOVE_UP\n",
      "5 ActionType.DESTROY SubActionType.DESTROY_DOWN\n",
      "6 ActionType.MOVE SubActionType.MOVE_RIGHT\n",
      "7 ActionType.MOVE SubActionType.MOVE_DOWN_LEFT\n",
      "348 202\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = ProconJumanji(game_options, map, craftsmen)\n",
    "\n",
    "random_key = jax.random.PRNGKey(0)\n",
    "key1, key2 = jax.random.split(random_key)\n",
    "batch_size = 1\n",
    "\n",
    "keys = jax.random.split(key1, batch_size)\n",
    "state, timestep = env.reset(keys[0])\n",
    "\n",
    "def game_actions_to_env_actions(all_turns_actions) -> list[list[EnvAction]]:\n",
    "    env_all_turns_actions: list[list[EnvAction]] = []\n",
    "    for actions in all_turns_actions:\n",
    "        turn_actions: list[EnvAction] = []\n",
    "        for action in actions:\n",
    "            turn_actions.append(EnvAction(action.subActionType.value, action.craftsmanId))\n",
    "        env_all_turns_actions.append(turn_actions)\n",
    "            \n",
    "    return env_all_turns_actions\n",
    "\n",
    "env_actions = game_actions_to_env_actions(actions)\n",
    "\n",
    "state_list = [state]\n",
    "\n",
    "for i, actions_in_turn in enumerate(env_actions):\n",
    "    # print(actions_in_turn)\n",
    "    state, timestep = env.step(state, actions_in_turn)\n",
    "    state_list.append(state)\n",
    "env.animate(state_list, interval=200, save_path=f'records/test.gif')\n",
    "env.render(state_list[-1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObservationSpec(\n",
       "\tis_pond=BoundedArray(shape=(25, 25), dtype=dtype('bool'), name='is_pond', minimum=Array(False, dtype=bool), maximum=Array(True, dtype=bool)),\n",
       "\tis_castle=BoundedArray(shape=(25, 25), dtype=dtype('bool'), name='is_castle', minimum=Array(False, dtype=bool), maximum=Array(True, dtype=bool)),\n",
       "\thas_t1_wall=BoundedArray(shape=(25, 25), dtype=dtype('bool'), name='has_t1_wall', minimum=Array(False, dtype=bool), maximum=Array(True, dtype=bool)),\n",
       "\thas_t2_wall=BoundedArray(shape=(25, 25), dtype=dtype('bool'), name='has_t2_wall', minimum=Array(False, dtype=bool), maximum=Array(True, dtype=bool)),\n",
       "\thas_t1_craftsman=BoundedArray(shape=(25, 25), dtype=dtype('bool'), name='has_t1_craftsman', minimum=Array(False, dtype=bool), maximum=Array(True, dtype=bool)),\n",
       "\thas_t2_craftsman=BoundedArray(shape=(25, 25), dtype=dtype('bool'), name='has_t2_craftsman', minimum=Array(False, dtype=bool), maximum=Array(True, dtype=bool)),\n",
       "\tis_t1_close_territory=BoundedArray(shape=(25, 25), dtype=dtype('bool'), name='is_t1_close_territory', minimum=Array(False, dtype=bool), maximum=Array(True, dtype=bool)),\n",
       "\tis_t2_close_territory=BoundedArray(shape=(25, 25), dtype=dtype('bool'), name='is_t2_close_territory', minimum=Array(False, dtype=bool), maximum=Array(True, dtype=bool)),\n",
       "\tis_t1_open_territory=BoundedArray(shape=(25, 25), dtype=dtype('bool'), name='is_t1_open_territory', minimum=Array(False, dtype=bool), maximum=Array(True, dtype=bool)),\n",
       "\tis_t2_open_territory=BoundedArray(shape=(25, 25), dtype=dtype('bool'), name='is_t2_open_territory', minimum=Array(False, dtype=bool), maximum=Array(True, dtype=bool)),\n",
       "\tagents=MultiDiscreteArray(shape=(8, 4), dtype=dtype('int32'), name='agents', minimum=Array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int32), maximum=Array([[24, 24,  7,  1],\n",
       "       [24, 24,  7,  1],\n",
       "       [24, 24,  7,  1],\n",
       "       [24, 24,  7,  1],\n",
       "       [24, 24,  7,  1],\n",
       "       [24, 24,  7,  1],\n",
       "       [24, 24,  7,  1],\n",
       "       [24, 24,  7,  1]], dtype=int32), num_values=Array([[25, 25,  8,  2],\n",
       "       [25, 25,  8,  2],\n",
       "       [25, 25,  8,  2],\n",
       "       [25, 25,  8,  2],\n",
       "       [25, 25,  8,  2],\n",
       "       [25, 25,  8,  2],\n",
       "       [25, 25,  8,  2],\n",
       "       [25, 25,  8,  2]], dtype=int32)),\n",
       "\tcurrent_turn=BoundedArray(shape=(), dtype=dtype('int32'), name='current_turn', minimum=Array(0, dtype=int32), maximum=Array(70, dtype=int32)),\n",
       "\tremaining_turns=BoundedArray(shape=(), dtype=dtype('int32'), name='remaining_turns', minimum=Array(0, dtype=int32), maximum=Array(70, dtype=int32)),\n",
       "\tis_t1_turn=BoundedArray(shape=(), dtype=dtype('bool'), name='is_t1_turn', minimum=Array(False, dtype=bool), maximum=Array(True, dtype=bool)),\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, Sequence, Tuple\n",
    "from colorama import Fore, Style\n",
    "\n",
    "import optax\n",
    "from optax._src.base import OptState\n",
    "import chex\n",
    "import distrax\n",
    "import flax.linen as nn\n",
    "from flax import struct\n",
    "from flax.core.frozen_dict import FrozenDict\n",
    "from flax.linen.initializers import constant, orthogonal\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "# Env requirements\n",
    "import jumanji\n",
    "from jumanji.env import Environment\n",
    "from jumanji import specs\n",
    "from jumanji.wrappers import AutoResetWrapper\n",
    "\n",
    "# Mava Helpful functions and types\n",
    "from mava.utils.jax import merge_leading_dims\n",
    "from mava.wrappers.jumanji import (\n",
    "    AgentIDWrapper,\n",
    "    LogWrapper,\n",
    "    ObservationGlobalState,\n",
    "    RwareMultiAgentWithGlobalStateWrapper,\n",
    ")\n",
    "from mava.types import ExperimentOutput, LearnerState, OptStates, Params, PPOTransition\n",
    "from mava.evaluator import evaluator_setup\n",
    "\n",
    "# Plot requirements\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import time\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor Network.\"\"\"\n",
    "\n",
    "    action_dim: Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, observation: ProconObservation) -> distrax.Categorical:\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        x = observation.agents_view\n",
    "\n",
    "        actor_output = nn.Dense(128, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0))(x)\n",
    "        actor_output = nn.relu(actor_output)\n",
    "        actor_output = nn.Dense(128, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0))(\n",
    "            actor_output\n",
    "        )\n",
    "        actor_output = nn.relu(actor_output)\n",
    "        actor_output = nn.Dense(\n",
    "            self.action_dim, kernel_init=orthogonal(0.01), bias_init=constant(0.0)\n",
    "        )(actor_output)\n",
    "\n",
    "        masked_logits = jnp.where(\n",
    "            observation.action_mask,\n",
    "            actor_output,\n",
    "            jnp.finfo(jnp.float32).min,\n",
    "        )\n",
    "        actor_policy = distrax.Categorical(logits=masked_logits)\n",
    "\n",
    "        return actor_policy\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic Network.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, observation: ProconObservation) -> chex.Array:\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "\n",
    "        critic_output = nn.Dense(128, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0))(\n",
    "            observation.global_state\n",
    "        )\n",
    "        critic_output = nn.relu(critic_output)\n",
    "        critic_output = nn.Dense(128, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0))(\n",
    "            critic_output\n",
    "        )\n",
    "        critic_output = nn.relu(critic_output)\n",
    "        critic_output = nn.Dense(1, kernel_init=orthogonal(1.0), bias_init=constant(0.0))(\n",
    "            critic_output\n",
    "        )\n",
    "\n",
    "        return jnp.squeeze(critic_output, axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner_fn(\n",
    "    env: jumanji.Environment,\n",
    "    apply_fns: Tuple[Callable, Callable],\n",
    "    update_fns: Tuple[Callable, Callable],\n",
    "    config: Dict,\n",
    ") -> Callable:\n",
    "    \"\"\"Get the learner function.\"\"\"\n",
    "\n",
    "    # Unpack apply and update functions.\n",
    "    actor_apply_fn, critic_apply_fn = apply_fns\n",
    "    actor_update_fn, critic_update_fn = update_fns\n",
    "\n",
    "    def _update_step(learner_state: LearnerState, _: Any) -> Tuple[LearnerState, Tuple]:\n",
    "        \"\"\"A single update of the network.\n",
    "\n",
    "        This function steps the environment and records the trajectory batch for\n",
    "        training. It then calculates advantages and targets based on the recorded\n",
    "        trajectory and updates the actor and critic networks based on the calculated\n",
    "        losses.\n",
    "\n",
    "        Args:\n",
    "            learner_state (NamedTuple):\n",
    "                - params (Params): The current model parameters.\n",
    "                - opt_states (OptStates): The current optimizer states.\n",
    "                - rng (PRNGKey): The random number generator state.\n",
    "                - env_state (State): The environment state.\n",
    "                - last_timestep (TimeStep): The last timestep in the current trajectory.\n",
    "            _ (Any): The current metrics info.\n",
    "        \"\"\"\n",
    "\n",
    "        def _env_step(learner_state: LearnerState, _: Any) -> Tuple[LearnerState, PPOTransition]:\n",
    "            \"\"\"Step the environment.\"\"\"\n",
    "            params, opt_states, rng, env_state, last_timestep = learner_state\n",
    "\n",
    "            # SELECT ACTION\n",
    "            rng, policy_rng = jax.random.split(rng)\n",
    "            actor_policy = actor_apply_fn(params.actor_params, last_timestep.observation)\n",
    "            value = critic_apply_fn(params.critic_params, last_timestep.observation)\n",
    "            action = actor_policy.sample(seed=policy_rng)\n",
    "            log_prob = actor_policy.log_prob(action)\n",
    "\n",
    "            # STEP ENVIRONMENT\n",
    "            env_state, timestep = jax.vmap(env.step, in_axes=(0, 0))(env_state, action)\n",
    "\n",
    "            # LOG EPISODE METRICS\n",
    "            done, reward = jax.tree_util.tree_map(\n",
    "                lambda x: jnp.repeat(x, config[\"num_agents\"]).reshape(config[\"num_envs\"], -1),\n",
    "                (timestep.last(), timestep.reward),\n",
    "            )\n",
    "            info = {\n",
    "                \"episode_return\": env_state.episode_return_info,\n",
    "                \"episode_length\": env_state.episode_length_info,\n",
    "            }\n",
    "\n",
    "            transition = PPOTransition(\n",
    "                done, action, value, reward, log_prob, last_timestep.observation, info\n",
    "            )\n",
    "            learner_state = LearnerState(params, opt_states, rng, env_state, timestep)\n",
    "            return learner_state, transition\n",
    "\n",
    "        # STEP ENVIRONMENT FOR ROLLOUT LENGTH\n",
    "        learner_state, traj_batch = jax.lax.scan(\n",
    "            _env_step, learner_state, None, config[\"rollout_length\"]\n",
    "        )\n",
    "\n",
    "        # CALCULATE ADVANTAGE\n",
    "        params, opt_states, rng, env_state, last_timestep = learner_state\n",
    "        last_val = critic_apply_fn(params.critic_params, last_timestep.observation)\n",
    "\n",
    "        def _calculate_gae(\n",
    "            traj_batch: PPOTransition, last_val: chex.Array\n",
    "        ) -> Tuple[chex.Array, chex.Array]:\n",
    "            \"\"\"Calculate the GAE.\"\"\"\n",
    "\n",
    "            def _get_advantages(gae_and_next_value: Tuple, transition: PPOTransition) -> Tuple:\n",
    "                \"\"\"Calculate the GAE for a single transition.\"\"\"\n",
    "                gae, next_value = gae_and_next_value\n",
    "                done, value, reward = (\n",
    "                    transition.done,\n",
    "                    transition.value,\n",
    "                    transition.reward,\n",
    "                )\n",
    "                delta = reward + config[\"gamma\"] * next_value * (1 - done) - value\n",
    "                gae = delta + config[\"gamma\"] * config[\"gae_lambda\"] * (1 - done) * gae\n",
    "                return (gae, value), gae\n",
    "\n",
    "            _, advantages = jax.lax.scan(\n",
    "                _get_advantages,\n",
    "                (jnp.zeros_like(last_val), last_val),\n",
    "                traj_batch,\n",
    "                reverse=True,\n",
    "                unroll=16,\n",
    "            )\n",
    "            return advantages, advantages + traj_batch.value\n",
    "\n",
    "        advantages, targets = _calculate_gae(traj_batch, last_val)\n",
    "\n",
    "        def _update_epoch(update_state: Tuple, _: Any) -> Tuple:\n",
    "            \"\"\"Update the network for a single epoch.\"\"\"\n",
    "\n",
    "            def _update_minibatch(train_state: Tuple, batch_info: Tuple) -> Tuple:\n",
    "                \"\"\"Update the network for a single minibatch.\"\"\"\n",
    "\n",
    "                # UNPACK TRAIN STATE AND BATCH INFO\n",
    "                params, opt_states = train_state\n",
    "                traj_batch, advantages, targets = batch_info\n",
    "\n",
    "                def _actor_loss_fn(\n",
    "                    actor_params: FrozenDict,\n",
    "                    actor_opt_state: OptState,\n",
    "                    traj_batch: PPOTransition,\n",
    "                    gae: chex.Array,\n",
    "                ) -> Tuple:\n",
    "                    \"\"\"Calculate the actor loss.\"\"\"\n",
    "                    # RERUN NETWORK\n",
    "                    actor_policy = actor_apply_fn(actor_params, traj_batch.obs)\n",
    "                    log_prob = actor_policy.log_prob(traj_batch.action)\n",
    "\n",
    "                    # CALCULATE ACTOR LOSS\n",
    "                    ratio = jnp.exp(log_prob - traj_batch.log_prob)\n",
    "                    gae = (gae - gae.mean()) / (gae.std() + 1e-8)\n",
    "                    loss_actor1 = ratio * gae\n",
    "                    loss_actor2 = (\n",
    "                        jnp.clip(\n",
    "                            ratio,\n",
    "                            1.0 - config[\"clip_eps\"],\n",
    "                            1.0 + config[\"clip_eps\"],\n",
    "                        )\n",
    "                        * gae\n",
    "                    )\n",
    "                    loss_actor = -jnp.minimum(loss_actor1, loss_actor2)\n",
    "                    loss_actor = loss_actor.mean()\n",
    "                    entropy = actor_policy.entropy().mean()\n",
    "\n",
    "                    total_loss_actor = loss_actor - config[\"ent_coef\"] * entropy\n",
    "                    return total_loss_actor, (loss_actor, entropy)\n",
    "\n",
    "                def _critic_loss_fn(\n",
    "                    critic_params: FrozenDict,\n",
    "                    critic_opt_state: OptState,\n",
    "                    traj_batch: PPOTransition,\n",
    "                    targets: chex.Array,\n",
    "                ) -> Tuple:\n",
    "                    \"\"\"Calculate the critic loss.\"\"\"\n",
    "                    # RERUN NETWORK\n",
    "                    value = critic_apply_fn(critic_params, traj_batch.obs)\n",
    "\n",
    "                    # CALCULATE VALUE LOSS\n",
    "                    value_pred_clipped = traj_batch.value + (value - traj_batch.value).clip(\n",
    "                        -config[\"clip_eps\"], config[\"clip_eps\"]\n",
    "                    )\n",
    "                    value_losses = jnp.square(value - targets)\n",
    "                    value_losses_clipped = jnp.square(value_pred_clipped - targets)\n",
    "                    value_loss = 0.5 * jnp.maximum(value_losses, value_losses_clipped).mean()\n",
    "\n",
    "                    critic_total_loss = config[\"vf_coef\"] * value_loss\n",
    "                    return critic_total_loss, (value_loss)\n",
    "\n",
    "                # CALCULATE ACTOR LOSS\n",
    "                actor_grad_fn = jax.value_and_grad(_actor_loss_fn, has_aux=True)\n",
    "                actor_loss_info, actor_grads = actor_grad_fn(\n",
    "                    params.actor_params, opt_states.actor_opt_state, traj_batch, advantages\n",
    "                )\n",
    "\n",
    "                # CALCULATE CRITIC LOSS\n",
    "                critic_grad_fn = jax.value_and_grad(_critic_loss_fn, has_aux=True)\n",
    "                critic_loss_info, critic_grads = critic_grad_fn(\n",
    "                    params.critic_params, opt_states.critic_opt_state, traj_batch, targets\n",
    "                )\n",
    "\n",
    "                # Compute the parallel mean (pmean) over the batch.\n",
    "                # This calculation is inspired by the Anakin architecture demo notebook.\n",
    "                # available at https://tinyurl.com/26tdzs5x\n",
    "                # This pmean could be a regular mean as the batch axis is on the same device.\n",
    "                actor_grads, actor_loss_info = jax.lax.pmean(\n",
    "                    (actor_grads, actor_loss_info), axis_name=\"batch\"\n",
    "                )\n",
    "                # pmean over devices.\n",
    "                actor_grads, actor_loss_info = jax.lax.pmean(\n",
    "                    (actor_grads, actor_loss_info), axis_name=\"device\"\n",
    "                )\n",
    "\n",
    "                critic_grads, critic_loss_info = jax.lax.pmean(\n",
    "                    (critic_grads, critic_loss_info), axis_name=\"batch\"\n",
    "                )\n",
    "                # pmean over devices.\n",
    "                critic_grads, critic_loss_info = jax.lax.pmean(\n",
    "                    (critic_grads, critic_loss_info), axis_name=\"device\"\n",
    "                )\n",
    "\n",
    "                # UPDATE ACTOR PARAMS AND OPTIMISER STATE\n",
    "                actor_updates, actor_new_opt_state = actor_update_fn(\n",
    "                    actor_grads, opt_states.actor_opt_state\n",
    "                )\n",
    "                actor_new_params = optax.apply_updates(params.actor_params, actor_updates)\n",
    "\n",
    "                # UPDATE CRITIC PARAMS AND OPTIMISER STATE\n",
    "                critic_updates, critic_new_opt_state = critic_update_fn(\n",
    "                    critic_grads, opt_states.critic_opt_state\n",
    "                )\n",
    "                critic_new_params = optax.apply_updates(params.critic_params, critic_updates)\n",
    "\n",
    "                new_params = Params(actor_new_params, critic_new_params)\n",
    "                new_opt_state = OptStates(actor_new_opt_state, critic_new_opt_state)\n",
    "\n",
    "                # PACK LOSS INFO\n",
    "                total_loss = actor_loss_info[0] + critic_loss_info[0]\n",
    "                value_loss = critic_loss_info[1]\n",
    "                actor_loss = actor_loss_info[1][0]\n",
    "                entropy = actor_loss_info[1][1]\n",
    "                loss_info = (\n",
    "                    total_loss,\n",
    "                    (value_loss, actor_loss, entropy),\n",
    "                )\n",
    "\n",
    "                return (new_params, new_opt_state), loss_info\n",
    "\n",
    "            params, opt_states, traj_batch, advantages, targets, rng = update_state\n",
    "            rng, shuffle_rng = jax.random.split(rng)\n",
    "\n",
    "            # SHUFFLE MINIBATCHES\n",
    "            batch_size = config[\"rollout_length\"] * config[\"num_envs\"]\n",
    "            permutation = jax.random.permutation(shuffle_rng, batch_size)\n",
    "            batch = (traj_batch, advantages, targets)\n",
    "            batch = jax.tree_util.tree_map(lambda x: merge_leading_dims(x, 2), batch)\n",
    "            shuffled_batch = jax.tree_util.tree_map(\n",
    "                lambda x: jnp.take(x, permutation, axis=0), batch\n",
    "            )\n",
    "            minibatches = jax.tree_util.tree_map(\n",
    "                lambda x: jnp.reshape(x, [config[\"num_minibatches\"], -1] + list(x.shape[1:])),\n",
    "                shuffled_batch,\n",
    "            )\n",
    "\n",
    "            # UPDATE MINIBATCHES\n",
    "            (params, opt_states), loss_info = jax.lax.scan(\n",
    "                _update_minibatch, (params, opt_states), minibatches\n",
    "            )\n",
    "\n",
    "            update_state = (params, opt_states, traj_batch, advantages, targets, rng)\n",
    "            return update_state, loss_info\n",
    "\n",
    "        update_state = (params, opt_states, traj_batch, advantages, targets, rng)\n",
    "\n",
    "        # UPDATE EPOCHS\n",
    "        update_state, loss_info = jax.lax.scan(\n",
    "            _update_epoch, update_state, None, config[\"ppo_epochs\"]\n",
    "        )\n",
    "\n",
    "        params, opt_states, traj_batch, advantages, targets, rng = update_state\n",
    "        learner_state = LearnerState(params, opt_states, rng, env_state, last_timestep)\n",
    "        metric = traj_batch.info\n",
    "        return learner_state, (metric, loss_info)\n",
    "\n",
    "    def learner_fn(learner_state: LearnerState) -> ExperimentOutput:\n",
    "        \"\"\"Learner function.\n",
    "\n",
    "        This function represents the learner, it updates the network parameters\n",
    "        by iteratively applying the `_update_step` function for a fixed number of\n",
    "        updates. The `_update_step` function is vectorized over a batch of inputs.\n",
    "\n",
    "        Args:\n",
    "            learner_state (NamedTuple):\n",
    "                - params (Params): The initial model parameters.\n",
    "                - opt_states (OptStates): The initial optimizer states.\n",
    "                - rng (chex.PRNGKey): The random number generator state.\n",
    "                - env_state (LogEnvState): The environment state.\n",
    "                - timesteps (TimeStep): The initial timestep in the initial trajectory.\n",
    "        \"\"\"\n",
    "\n",
    "        batched_update_step = jax.vmap(_update_step, in_axes=(0, None), axis_name=\"batch\")\n",
    "\n",
    "        learner_state, (metric, loss_info) = jax.lax.scan(\n",
    "            batched_update_step, learner_state, None, config[\"num_updates_per_eval\"]\n",
    "        )\n",
    "        total_loss, (value_loss, loss_actor, entropy) = loss_info\n",
    "        return ExperimentOutput(\n",
    "            learner_state=learner_state,\n",
    "            episodes_info=metric,\n",
    "            total_loss=total_loss,\n",
    "            value_loss=value_loss,\n",
    "            loss_actor=loss_actor,\n",
    "            entropy=entropy,\n",
    "        )\n",
    "\n",
    "    return learner_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learner_setup(\n",
    "    env: ProconJumanji, rngs: chex.Array, config: Dict\n",
    ") -> Tuple[Callable, Actor, LearnerState]:\n",
    "    \"\"\"Initialise learner_fn, network, optimiser, environment and states.\"\"\"\n",
    "    # Get available TPU cores.\n",
    "    n_devices = len(jax.devices())\n",
    "\n",
    "    # Get number of actions and agents.\n",
    "    num_actions = 17\n",
    "    num_agents = env.action_spec().shape[0]\n",
    "    print(f\"num_agents: {num_agents}. Setting num_agents to config.\")\n",
    "    \n",
    "    config[\"num_agents\"] = num_agents\n",
    "\n",
    "    # PRNG keys.\n",
    "    rng, rng_p = rngs\n",
    "\n",
    "    # Define network and optimiser.\n",
    "    actor_network = Actor(num_actions)\n",
    "    critic_network = Critic()\n",
    "    actor_optim = optax.chain(\n",
    "        optax.clip_by_global_norm(config[\"max_grad_norm\"]),\n",
    "        optax.adam(config[\"actor_lr\"], eps=1e-5),\n",
    "    )\n",
    "    critic_optim = optax.chain(\n",
    "        optax.clip_by_global_norm(config[\"max_grad_norm\"]),\n",
    "        optax.adam(config[\"critic_lr\"], eps=1e-5),\n",
    "    )\n",
    "\n",
    "    # Initialise observation.\n",
    "    obs = env.observation_spec().generate_value()\n",
    "    # Select only obs for a single agent.\n",
    "    # init_x = ObservationGlobalState(\n",
    "    #     agents_view=obs.agents_view[0],\n",
    "    #     action_mask=obs.action_mask[0],\n",
    "    #     global_state=obs.global_state[0],\n",
    "    #     step_count=obs.current_turn,\n",
    "    # )\n",
    "    init_x = obs\n",
    "    init_x = jax.tree_util.tree_map(lambda x: x[None, ...], init_x)\n",
    "\n",
    "    # Initialise actor params and optimiser state.\n",
    "    actor_params = actor_network.init(rng_p, init_x)\n",
    "    actor_opt_state = actor_optim.init(actor_params)\n",
    "\n",
    "    # Initialise critic params and optimiser state.\n",
    "    critic_params = critic_network.init(rng_p, init_x)\n",
    "    critic_opt_state = critic_optim.init(critic_params)\n",
    "\n",
    "    # Vmap network apply function over number of agents.\n",
    "    vmapped_actor_network_apply_fn = jax.vmap(\n",
    "        actor_network.apply,\n",
    "        in_axes=(None, 1),\n",
    "        out_axes=(1),\n",
    "    )\n",
    "    vmapped_critic_network_apply_fn = jax.vmap(\n",
    "        critic_network.apply,\n",
    "        in_axes=(None, 1),\n",
    "        out_axes=(1),\n",
    "    )\n",
    "\n",
    "    # Pack apply and update functions.\n",
    "    apply_fns = (vmapped_actor_network_apply_fn, vmapped_critic_network_apply_fn)\n",
    "    update_fns = (actor_optim.update, critic_optim.update)\n",
    "\n",
    "    # Get batched iterated update and replicate it to pmap it over cores.\n",
    "    learn = get_learner_fn(env, apply_fns, update_fns, config)\n",
    "    learn = jax.pmap(learn, axis_name=\"device\")\n",
    "\n",
    "    # Broadcast params and optimiser state to cores and batch.\n",
    "    broadcast = lambda x: jnp.broadcast_to(x, (n_devices, config[\"update_batch_size\"]) + x.shape)\n",
    "    actor_params = jax.tree_map(broadcast, actor_params)\n",
    "    actor_opt_state = jax.tree_map(broadcast, actor_opt_state)\n",
    "    critic_params = jax.tree_map(broadcast, critic_params)\n",
    "    critic_opt_state = jax.tree_map(broadcast, critic_opt_state)\n",
    "\n",
    "    # Initialise environment states and timesteps.\n",
    "    rng, *env_rngs = jax.random.split(\n",
    "        rng, n_devices * config[\"update_batch_size\"] * config[\"num_envs\"] + 1\n",
    "    )\n",
    "    env_states, timesteps = jax.vmap(env.reset, in_axes=(0))(\n",
    "        jnp.stack(env_rngs),\n",
    "    )\n",
    "\n",
    "    # Split rngs for each core.\n",
    "    rng, *step_rngs = jax.random.split(rng, n_devices * config[\"update_batch_size\"] + 1)\n",
    "\n",
    "    # Add dimension to pmap over.\n",
    "    reshape_step_rngs = lambda x: x.reshape((n_devices, config[\"update_batch_size\"]) + x.shape[1:])\n",
    "    step_rngs = reshape_step_rngs(jnp.stack(step_rngs))\n",
    "    reshape_states = lambda x: x.reshape(\n",
    "        (n_devices, config[\"update_batch_size\"], config[\"num_envs\"]) + x.shape[1:]\n",
    "    )\n",
    "    env_states = jax.tree_util.tree_map(reshape_states, env_states)\n",
    "    timesteps = jax.tree_util.tree_map(reshape_states, timesteps)\n",
    "\n",
    "    params = Params(actor_params, critic_params)\n",
    "    opt_states = OptStates(actor_opt_state, critic_opt_state)\n",
    "\n",
    "    init_learner_state = LearnerState(params, opt_states, step_rngs, env_states, timesteps)\n",
    "    return learn, actor_network, init_learner_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(metrics, ep_returns, start_time):\n",
    "      plt.figure(figsize=(8, 4))\n",
    "      clear_output(wait=True)\n",
    "\n",
    "      ep_returns.append(metrics.episodes_info[\"episode_return\"].mean())\n",
    "      # Plot the data\n",
    "      plt.plot(np.linspace(0, (time.time()-start_time)/ 60.0, len(list(ep_returns))),list(ep_returns))\n",
    "      plt.xlabel('Run Time [Minutes]')\n",
    "      plt.ylabel('Episode Return')\n",
    "      plt.title(f'Robotic Warehouse with 4 Agents')\n",
    "      # Show the plot\n",
    "      plt.show()\n",
    "      return ep_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"actor_lr\": 2.5e-4,\n",
    "    \"critic_lr\": 2.5e-4,\n",
    "    \"update_batch_size\": 2,\n",
    "    \"rollout_length\": 128,\n",
    "    \"num_updates\": 150,\n",
    "    \"num_envs\": 512,\n",
    "    \"ppo_epochs\": 16,\n",
    "    \"num_minibatches\": 32,\n",
    "    \"gamma\": 0.99,\n",
    "    \"gae_lambda\": 0.95,\n",
    "    \"clip_eps\": 0.2,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"vf_coef\": 0.5,\n",
    "    \"max_grad_norm\": 0.5,\n",
    "    \"env_name\": \"Procon-v0\",\n",
    "    \"num_eval_episodes\": 32,\n",
    "    \"num_evaluation\": 50,\n",
    "    \"evaluation_greedy\": False,\n",
    "    \"add_agent_id\": True,\n",
    "    \"seed\":42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'go' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m env \u001b[39m=\u001b[39m ProconJumanji(go, map_formatted, craftsmen_formatted)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m env \u001b[39m=\u001b[39m AutoResetWrapper(env)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m env \u001b[39m=\u001b[39m LogWrapper(env)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'go' is not defined"
     ]
    }
   ],
   "source": [
    "env = ProconJumanji(go, map_formatted, craftsmen_formatted)\n",
    "env = AutoResetWrapper(env)\n",
    "env = LogWrapper(env)\n",
    "eval_env = ProconJumanji(go, map_formatted, craftsmen_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_agents: 8. Setting num_agents to config.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ProconObservation' object has no attribute 'agents_view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb Cell 22\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m rng, rng_e, rng_p \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39msplit(jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mPRNGKey(config[\u001b[39m\"\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m\"\u001b[39m]), num\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Setup learner.\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m learn, actor_network, learner_state \u001b[39m=\u001b[39m learner_setup(env, (rng, rng_p), config)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Setup evaluator.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m evaluator, absolute_metric_evaluator, (trained_params, eval_rngs) \u001b[39m=\u001b[39m evaluator_setup(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         eval_env\u001b[39m=\u001b[39meval_env,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m         rng_e\u001b[39m=\u001b[39mrng_e,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m         config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m )\n",
      "\u001b[1;32m/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb Cell 22\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m init_x \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_map(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39mNone\u001b[39;00m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m], init_x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# Initialise actor params and optimiser state.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m actor_params \u001b[39m=\u001b[39m actor_network\u001b[39m.\u001b[39;49minit(rng_p, init_x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m actor_opt_state \u001b[39m=\u001b[39m actor_optim\u001b[39m.\u001b[39minit(actor_params)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# Initialise critic params and optimiser state.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "\u001b[1;32m/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb Cell 22\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m@nn\u001b[39m\u001b[39m.\u001b[39mcompact\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, observation: ProconObservation) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m distrax\u001b[39m.\u001b[39mCategorical:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward pass.\"\"\"\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     x \u001b[39m=\u001b[39m observation\u001b[39m.\u001b[39;49magents_view\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     actor_output \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDense(\u001b[39m128\u001b[39m, kernel_init\u001b[39m=\u001b[39morthogonal(np\u001b[39m.\u001b[39msqrt(\u001b[39m2\u001b[39m)), bias_init\u001b[39m=\u001b[39mconstant(\u001b[39m0.0\u001b[39m))(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/f/procon-2023/cpp-simulator/Procon2023/procon-jumanji.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     actor_output \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mrelu(actor_output)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ProconObservation' object has no attribute 'agents_view'"
     ]
    }
   ],
   "source": [
    "# PRNG keys.\n",
    "rng, rng_e, rng_p = jax.random.split(jax.random.PRNGKey(config[\"seed\"]), num=3)\n",
    "\n",
    "# Setup learner.\n",
    "learn, actor_network, learner_state = learner_setup(env, (rng, rng_p), config)\n",
    "\n",
    "# Setup evaluator.\n",
    "evaluator, absolute_metric_evaluator, (trained_params, eval_rngs) = evaluator_setup(\n",
    "        eval_env=eval_env,\n",
    "        rng_e=rng_e,\n",
    "        network=actor_network,\n",
    "        params=learner_state.params.actor_params,\n",
    "        config=config,\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'procon-ai' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n procon-ai ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate total timesteps.\n",
    "n_devices = len(jax.devices())\n",
    "config[\"num_updates_per_eval\"] = config[\"num_updates\"] // config[\"num_evaluation\"]\n",
    "steps_per_rollout = (\n",
    "    n_devices\n",
    "    * config[\"num_updates_per_eval\"]\n",
    "    * config[\"rollout_length\"]\n",
    "    * config[\"update_batch_size\"]\n",
    "    * config[\"num_envs\"]\n",
    ")\n",
    "\n",
    "# Run experiment for a total number of evaluations.\n",
    "ep_returns=[]\n",
    "     \n",
    "\n",
    "\n",
    "learn(learner_state)\n",
    "\n",
    "# Compile the evaluator function\n",
    "_ = evaluator(trained_params, eval_rngs)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'procon-ai' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n procon-ai ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "for i in range(config[\"num_evaluation\"]):\n",
    "    # Train.\n",
    "    learner_output = learn(learner_state)\n",
    "    jax.block_until_ready(learner_output)\n",
    "\n",
    "\n",
    "    # Prepare for evaluation.\n",
    "    trained_params = jax.tree_util.tree_map(\n",
    "            lambda x: x[:, 0, ...],\n",
    "            learner_output.learner_state.params.actor_params,  # Select only actor params\n",
    "    )\n",
    "    rng_e, *eval_rngs = jax.random.split(rng_e, n_devices + 1)\n",
    "    eval_rngs = jnp.stack(eval_rngs)\n",
    "    eval_rngs = eval_rngs.reshape(n_devices, -1)\n",
    "\n",
    "    # Evaluate.\n",
    "    evaluator_output = evaluator(trained_params, eval_rngs)\n",
    "    jax.block_until_ready(evaluator_output)\n",
    "    ep_returns=plot_performance(evaluator_output, ep_returns, start_time)\n",
    "\n",
    "    # Update runner state to continue training.\n",
    "    learner_state = learner_output.learner_state\n",
    "\n",
    "# Return trained params to be used for rendering or testing.\n",
    "trained_params= jax.tree_util.tree_map(\n",
    "    lambda x: x[0, 0, ...], learner_output.learner_state.params.actor_params\n",
    ")\n",
    "print(f\"{Fore.CYAN}{Style.BRIGHT}MAPPO experiment completed{Style.RESET_ALL}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "procon-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
